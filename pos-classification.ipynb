{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5140f4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author\n",
       "id                                                               \n",
       "id26305  This process, however, afforded me no means of...    EAP\n",
       "id17569  It never once occurred to me that the fumbling...    HPL\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.dropna(axis=0)\n",
    "df.set_index('id', inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3216da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>this process however afforded me no means of a...</td>\n",
       "      <td>224</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "      <td>6.380952</td>\n",
       "      <td>4</td>\n",
       "      <td>[This, process, ,, however, ,, afforded, me, n...</td>\n",
       "      <td>[(This, DT), (process, NN), (,, ,), (however, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>[It, never, once, occurred, to, me, that, the,...</td>\n",
       "      <td>[(It, PRP), (never, RB), (once, RB), (occurred...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>in his left hand was a gold snuff box from whi...</td>\n",
       "      <td>195</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>5.947368</td>\n",
       "      <td>4</td>\n",
       "      <td>[In, his, left, hand, was, a, gold, snuff, box...</td>\n",
       "      <td>[(In, IN), (his, PRP$), (left, JJ), (hand, NN)...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "      <td>202</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>6.476190</td>\n",
       "      <td>3</td>\n",
       "      <td>[How, lovely, is, spring, As, we, looked, from...</td>\n",
       "      <td>[(How, WRB), (lovely, RB), (is, VBZ), (spring,...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>finding nothing else not even gold the superin...</td>\n",
       "      <td>170</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>2</td>\n",
       "      <td>[Finding, nothing, else, ,, not, even, gold, ,...</td>\n",
       "      <td>[(Finding, VBG), (nothing, NN), (else, RB), (,...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  \\\n",
       "id                                                                  \n",
       "id26305  This process, however, afforded me no means of...    EAP   \n",
       "id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id26305  this process however afforded me no means of a...     224     41   \n",
       "id17569  it never once occurred to me that the fumbling...      70     14   \n",
       "id11008  in his left hand was a gold snuff box from whi...     195     36   \n",
       "id27763  how lovely is spring as we looked from windsor...     202     34   \n",
       "id12958  finding nothing else not even gold the superin...     170     27   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  \\\n",
       "id                                                     \n",
       "id26305                  21         6.380952       4   \n",
       "id17569                   6         6.166667       0   \n",
       "id11008                  19         5.947368       4   \n",
       "id27763                  21         6.476190       3   \n",
       "id12958                  16         7.187500       2   \n",
       "\n",
       "                                                    tokens  \\\n",
       "id                                                           \n",
       "id26305  [This, process, ,, however, ,, afforded, me, n...   \n",
       "id17569  [It, never, once, occurred, to, me, that, the,...   \n",
       "id11008  [In, his, left, hand, was, a, gold, snuff, box...   \n",
       "id27763  [How, lovely, is, spring, As, we, looked, from...   \n",
       "id12958  [Finding, nothing, else, ,, not, even, gold, ,...   \n",
       "\n",
       "                                                       pos  adjectives  nouns  \\\n",
       "id                                                                              \n",
       "id26305  [(This, DT), (process, NN), (,, ,), (however, ...           2     10   \n",
       "id17569  [(It, PRP), (never, RB), (once, RB), (occurred...           1      2   \n",
       "id11008  [(In, IN), (his, PRP$), (left, JJ), (hand, NN)...           5     10   \n",
       "id27763  [(How, WRB), (lovely, RB), (is, VBZ), (spring,...           6     10   \n",
       "id12958  [(Finding, VBG), (nothing, NN), (else, RB), (,...           1      7   \n",
       "\n",
       "         verbs  \n",
       "id              \n",
       "id26305      6  \n",
       "id17569      2  \n",
       "id11008      4  \n",
       "id27763      5  \n",
       "id12958      5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "#creating a function to encapsulate preprocessing, to mkae it easy to replicate on  submission data\n",
    "def processing(df):\n",
    "    #lowering and removing punctuation\n",
    "    df['processed'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n",
    "    \n",
    "    #numerical feature engineering\n",
    "    #total length of sentence\n",
    "    df['length'] = df['processed'].apply(lambda x: len(x))\n",
    "    #get number of words\n",
    "    df['words'] = df['processed'].apply(lambda x: len(x.split(' ')))\n",
    "    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))\n",
    "    #get the average word length\n",
    "    df['avg_word_length'] = df['processed'].apply(lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len([len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n",
    "    #get the number of commas\n",
    "    df['commas'] = df['text'].apply(lambda x: x.count(','))\n",
    "    #tokenize\n",
    "    df['tokens'] = df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "    #add pos from nltk pos tagging library, where classfiers have already \n",
    "    #been taught to identify the part of speech for each word\n",
    "    df['pos'] = df['tokens'].apply(lambda x: nltk.pos_tag(x))\n",
    "    #get the number of adjectives using lambda function that gets part of speech\n",
    "    #added to text by pos_tag then makes a list of all the words that have the JJ identifier\n",
    "    #that denotes adjective -> the length gives us how many items there are in the list\n",
    "    df['adjectives'] = df['pos'].apply(lambda x: len([word for word, pos in x if pos.startswith('JJ')]))\n",
    "    #get number of nouns \n",
    "    df['nouns'] = df['pos'].apply(lambda x: len([word for word, pos in x if pos.startswith('NN')]))\n",
    "    #get number of verbs\n",
    "    df['verbs'] = df['pos'].apply(lambda x: len([word for word, pos in x if pos.startswith('VB')]))\n",
    "    return(df)\n",
    "\n",
    "df = processing(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c0fe8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>words_not_stopword</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>commas</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id19417</th>\n",
       "      <td>this panorama is indeed glorious and i should ...</td>\n",
       "      <td>91</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, panorama, is, indeed, glorious, ,, and,...</td>\n",
       "      <td>[(This, DT), (panorama, NN), (is, VBZ), (indee...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09522</th>\n",
       "      <td>there was a simple natural earnestness about h...</td>\n",
       "      <td>240</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>6.277778</td>\n",
       "      <td>4</td>\n",
       "      <td>[There, was, a, simple, ,, natural, earnestnes...</td>\n",
       "      <td>[(There, EX), (was, VBD), (a, DT), (simple, NN...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22732</th>\n",
       "      <td>who are you pray that i duc de lomelette princ...</td>\n",
       "      <td>387</td>\n",
       "      <td>74</td>\n",
       "      <td>38</td>\n",
       "      <td>5.552632</td>\n",
       "      <td>9</td>\n",
       "      <td>[Who, are, you, ,, pray, ,, that, I, ,, Duc, D...</td>\n",
       "      <td>[(Who, WP), (are, VBP), (you, PRP), (,, ,), (p...</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10351</th>\n",
       "      <td>he had gone in the carriage to the nearest tow...</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>0</td>\n",
       "      <td>[He, had, gone, in, the, carriage, to, the, ne...</td>\n",
       "      <td>[(He, PRP), (had, VBD), (gone, VBN), (in, IN),...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24580</th>\n",
       "      <td>there is no method in their proceedings beyond...</td>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>[There, is, no, method, in, their, proceedings...</td>\n",
       "      <td>[(There, EX), (is, VBZ), (no, DT), (method, NN...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 processed  length  words  \\\n",
       "id                                                                          \n",
       "id19417  this panorama is indeed glorious and i should ...      91     18   \n",
       "id09522  there was a simple natural earnestness about h...     240     44   \n",
       "id22732  who are you pray that i duc de lomelette princ...     387     74   \n",
       "id10351  he had gone in the carriage to the nearest tow...     118     24   \n",
       "id24580  there is no method in their proceedings beyond...      71     13   \n",
       "\n",
       "         words_not_stopword  avg_word_length  commas  \\\n",
       "id                                                     \n",
       "id19417                   6         6.666667       1   \n",
       "id09522                  18         6.277778       4   \n",
       "id22732                  38         5.552632       9   \n",
       "id10351                  11         5.363636       0   \n",
       "id24580                   5         7.000000       1   \n",
       "\n",
       "                                                    tokens  \\\n",
       "id                                                           \n",
       "id19417  [This, panorama, is, indeed, glorious, ,, and,...   \n",
       "id09522  [There, was, a, simple, ,, natural, earnestnes...   \n",
       "id22732  [Who, are, you, ,, pray, ,, that, I, ,, Duc, D...   \n",
       "id10351  [He, had, gone, in, the, carriage, to, the, ne...   \n",
       "id24580  [There, is, no, method, in, their, proceedings...   \n",
       "\n",
       "                                                       pos  adjectives  nouns  \\\n",
       "id                                                                              \n",
       "id19417  [(This, DT), (panorama, NN), (is, VBZ), (indee...           1      3   \n",
       "id09522  [(There, EX), (was, VBD), (a, DT), (simple, NN...           5     10   \n",
       "id22732  [(Who, WP), (are, VBP), (you, PRP), (,, ,), (p...           2     21   \n",
       "id10351  [(He, PRP), (had, VBD), (gone, VBN), (in, IN),...           1      8   \n",
       "id24580  [(There, EX), (is, VBZ), (no, DT), (method, NN...           0      4   \n",
       "\n",
       "         verbs  \n",
       "id              \n",
       "id19417      2  \n",
       "id09522      7  \n",
       "id22732     11  \n",
       "id10351      3  \n",
       "id24580      1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features= [c for c in df.columns.values if c  not in ['id','text','author']]\n",
    "numeric_features= [c for c in df.columns.values if c  not in ['id','text','author','processed']]\n",
    "target = 'author'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.33, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c185605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb3bd1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13117x21516 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 148061 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text = Pipeline([\n",
    "                ('selector', TextSelector(key='processed')),\n",
    "                ('tfidf', TfidfVectorizer( stop_words='english'))\n",
    "            ])\n",
    "\n",
    "text.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e896f784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50769254],\n",
       "       [ 0.88000324],\n",
       "       [ 2.24907223],\n",
       "       ...,\n",
       "       [-0.46112557],\n",
       "       [-0.14447015],\n",
       "       [-0.39593181]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "length =  Pipeline([\n",
    "                ('selector', NumberSelector(key='length')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "\n",
    "length.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3909f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here are the features\n",
    "words =  Pipeline([\n",
    "                ('selector', NumberSelector(key='words')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "words_not_stopword =  Pipeline([\n",
    "                ('selector', NumberSelector(key='words_not_stopword')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "avg_word_length =  Pipeline([\n",
    "                ('selector', NumberSelector(key='avg_word_length')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "commas =  Pipeline([\n",
    "                ('selector', NumberSelector(key='commas')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "adjectives =  Pipeline([\n",
    "                ('selector', NumberSelector(key='adjectives')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "nouns =  Pipeline([\n",
    "                ('selector', NumberSelector(key='nouns')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "verbs =  Pipeline([\n",
    "                ('selector', NumberSelector(key='verbs')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec8e54d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13117x21524 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 252997 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion([('text', text), \n",
    "                      ('length', length),\n",
    "                      ('words', words),\n",
    "                      ('words_not_stopword', words_not_stopword),\n",
    "                      ('avg_word_length', avg_word_length),\n",
    "                      ('commas', commas),\n",
    "                      ('adjectives', adjectives),\n",
    "                      ('nouns', nouns),\n",
    "                      ('verbs', verbs)\n",
    "                     ])\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33d90a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.77088866 0.77740321]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LogisticRegression(random_state = 42)),\n",
    "    #sets classifier to LR instead of Forest\n",
    "])\n",
    "\n",
    "scores = cross_val_score(pipeline, df[features], df[target], cv=2)\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "\n",
    "\n",
    "# 2 fold data: [0.77088866 0.77740321]\n",
    "\n",
    "# 10 fold data: [0.79213483 0.81358529 0.80081716 0.79213483 0.82686415 0.79009193\n",
    "# 0.79928498 0.81001021 0.81001021 0.8109351 ]\n",
    "\n",
    "# 20 fold data: [0.79162411 0.77630235 0.80898876 0.81511747 0.79366701 0.81001021\n",
    "# 0.79979571 0.79570991 0.80898876 0.82635342 0.7854954  0.79775281\n",
    "# 0.80796731 0.7834525  0.80694586 0.79877426 0.79673136 0.82737487\n",
    "# 0.81307457 0.80777096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f2b9bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'features', 'classifier', 'features__n_jobs', 'features__transformer_list', 'features__transformer_weights', 'features__verbose', 'features__text', 'features__length', 'features__words', 'features__words_not_stopword', 'features__avg_word_length', 'features__commas', 'features__adjectives', 'features__nouns', 'features__verbs', 'features__text__memory', 'features__text__steps', 'features__text__verbose', 'features__text__selector', 'features__text__tfidf', 'features__text__selector__key', 'features__text__tfidf__analyzer', 'features__text__tfidf__binary', 'features__text__tfidf__decode_error', 'features__text__tfidf__dtype', 'features__text__tfidf__encoding', 'features__text__tfidf__input', 'features__text__tfidf__lowercase', 'features__text__tfidf__max_df', 'features__text__tfidf__max_features', 'features__text__tfidf__min_df', 'features__text__tfidf__ngram_range', 'features__text__tfidf__norm', 'features__text__tfidf__preprocessor', 'features__text__tfidf__smooth_idf', 'features__text__tfidf__stop_words', 'features__text__tfidf__strip_accents', 'features__text__tfidf__sublinear_tf', 'features__text__tfidf__token_pattern', 'features__text__tfidf__tokenizer', 'features__text__tfidf__use_idf', 'features__text__tfidf__vocabulary', 'features__length__memory', 'features__length__steps', 'features__length__verbose', 'features__length__selector', 'features__length__standard', 'features__length__selector__key', 'features__length__standard__copy', 'features__length__standard__with_mean', 'features__length__standard__with_std', 'features__words__memory', 'features__words__steps', 'features__words__verbose', 'features__words__selector', 'features__words__standard', 'features__words__selector__key', 'features__words__standard__copy', 'features__words__standard__with_mean', 'features__words__standard__with_std', 'features__words_not_stopword__memory', 'features__words_not_stopword__steps', 'features__words_not_stopword__verbose', 'features__words_not_stopword__selector', 'features__words_not_stopword__standard', 'features__words_not_stopword__selector__key', 'features__words_not_stopword__standard__copy', 'features__words_not_stopword__standard__with_mean', 'features__words_not_stopword__standard__with_std', 'features__avg_word_length__memory', 'features__avg_word_length__steps', 'features__avg_word_length__verbose', 'features__avg_word_length__selector', 'features__avg_word_length__standard', 'features__avg_word_length__selector__key', 'features__avg_word_length__standard__copy', 'features__avg_word_length__standard__with_mean', 'features__avg_word_length__standard__with_std', 'features__commas__memory', 'features__commas__steps', 'features__commas__verbose', 'features__commas__selector', 'features__commas__standard', 'features__commas__selector__key', 'features__commas__standard__copy', 'features__commas__standard__with_mean', 'features__commas__standard__with_std', 'features__adjectives__memory', 'features__adjectives__steps', 'features__adjectives__verbose', 'features__adjectives__selector', 'features__adjectives__standard', 'features__adjectives__selector__key', 'features__adjectives__standard__copy', 'features__adjectives__standard__with_mean', 'features__adjectives__standard__with_std', 'features__nouns__memory', 'features__nouns__steps', 'features__nouns__verbose', 'features__nouns__selector', 'features__nouns__standard', 'features__nouns__selector__key', 'features__nouns__standard__copy', 'features__nouns__standard__with_mean', 'features__nouns__standard__with_std', 'features__verbs__memory', 'features__verbs__steps', 'features__verbs__verbose', 'features__verbs__selector', 'features__verbs__standard', 'features__verbs__selector__key', 'features__verbs__standard__copy', 'features__verbs__standard__with_mean', 'features__verbs__standard__with_std', 'classifier__C', 'classifier__class_weight', 'classifier__dual', 'classifier__fit_intercept', 'classifier__intercept_scaling', 'classifier__l1_ratio', 'classifier__max_iter', 'classifier__multi_class', 'classifier__n_jobs', 'classifier__penalty', 'classifier__random_state', 'classifier__solver', 'classifier__tol', 'classifier__verbose', 'classifier__warm_start'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad400dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=8,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         TextSelector(key='processed')),\n",
       "                                                                                        ('tfidf',\n",
       "                                                                                         TfidfVectorizer(stop_words='english'))])),\n",
       "                                                                       ('length',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberSelector(key='length')),\n",
       "                                                                                        ('standard',\n",
       "                                                                                         StandardScaler())])),\n",
       "                                                                       ('words',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberS...\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberSelector(key='nouns')),\n",
       "                                                                                        ('standard',\n",
       "                                                                                         StandardScaler())])),\n",
       "                                                                       ('verbs',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberSelector(key='verbs')),\n",
       "                                                                                        ('standard',\n",
       "                                                                                         StandardScaler())]))])),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             param_grid={'features__text__tfidf__max_df': [0.9, 0.95],\n",
       "                         'features__text__tfidf__ngram_range': [(1, 1),\n",
       "                                                                (1, 2)]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "hyperparameters = { 'features__text__tfidf__max_df': [0.9, 0.95],\n",
    "                    'features__text__tfidf__ngram_range': [(1,1), (1,2)],\n",
    "                    #'classifier__max_depth': [50, 70],\n",
    "                  #'classifier__min_samples_leaf': [1,2]\n",
    "                  }\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=8)\n",
    " \n",
    "# Fit and tune model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae955aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features__text__tfidf__max_df': 0.9,\n",
       " 'features__text__tfidf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f324d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         EAP       0.74      0.84      0.79      2587\n",
      "         HPL       0.81      0.75      0.77      1852\n",
      "         MWS       0.82      0.74      0.78      2023\n",
      "\n",
      "    accuracy                           0.78      6462\n",
      "   macro avg       0.79      0.77      0.78      6462\n",
      "weighted avg       0.79      0.78      0.78      6462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#refitting on entire training data using best settings\n",
    "clf.refit\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "probs = clf.predict_proba(X_test)\n",
    "\n",
    "np.mean(preds == y_test)\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05428785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>0.255812</td>\n",
       "      <td>0.075432</td>\n",
       "      <td>0.668755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>0.858864</td>\n",
       "      <td>0.036704</td>\n",
       "      <td>0.104432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>0.241647</td>\n",
       "      <td>0.686072</td>\n",
       "      <td>0.072282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>0.676866</td>\n",
       "      <td>0.205296</td>\n",
       "      <td>0.117838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>0.689335</td>\n",
       "      <td>0.227963</td>\n",
       "      <td>0.082702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EAP       HPL       MWS\n",
       "id                                   \n",
       "id02310  0.255812  0.075432  0.668755\n",
       "id24541  0.858864  0.036704  0.104432\n",
       "id00134  0.241647  0.686072  0.072282\n",
       "id27757  0.676866  0.205296  0.117838\n",
       "id04081  0.689335  0.227963  0.082702"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('test.csv')\n",
    "\n",
    "#preprocessing\n",
    "submission = processing(submission)\n",
    "predictions = clf.predict_proba(submission)\n",
    "\n",
    "preds = pd.DataFrame(data=predictions, columns = clf.best_estimator_.named_steps['classifier'].classes_)\n",
    "\n",
    "#generating a submission file\n",
    "result = pd.concat([submission[['id']], preds], axis=1)\n",
    "result.set_index('id', inplace = True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8c27f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we definetly have a lot more stored elements since we are now holding data for three more\n",
    "#features, I definetly thought this would reduce the preformance as they take up more memory\n",
    "#and are three new classes to store. I think the precision increased for the model which is good\n",
    "#so I guess when it comes to the addition of new features there will be a trade off when\n",
    "#it comes to preformance vs precision, the preformance with less features is definetly\n",
    "#faster so it comes down to what we hope to gain from the classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
